{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Modules:"
      ],
      "metadata": {
        "id": "UrihGuJuaMj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import module\n",
        "!pip install bs4\n",
        "!pip install requests\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "n7qvFV0NaKw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module : ***getdata***:\n",
        "To Scrape data and get the string\n",
        "\n",
        "Module : ***html_code***:\n",
        "Html code using parse, pass the URL into getdata function and return HTML code\n",
        "\n",
        "Module : ***job_data***:\n",
        "Filter job data using find_all function, find the HTML tag with find() and convert into string\n",
        "\n",
        "Module :***company_data***:\n",
        "Find the HTML tag with tag() and convert into string\n",
        "\n"
      ],
      "metadata": {
        "id": "oqReuyvraUO7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tCqpsIK5NV6",
        "outputId": "bd476c8d-3aee-4f27-d8b4-920e1f820ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ]
        }
      ],
      "source": [
        "def getdata(url):\n",
        "  r = requests.get(url, data= None, headers={\n",
        "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
        "      'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
        "      'Chrome/23.0.1271.64 Safari/537.11',\n",
        "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "      'Accept-Encoding': 'none',\n",
        "      'Accept-Language': 'en-US,en;q=0.8',\n",
        "      'Connection': 'keep-alive'\n",
        "    })\n",
        "  return r.text\n",
        "\n",
        "def html_code(url):\n",
        "\thtmldata = getdata(url)\n",
        "\tsoup = BeautifulSoup(htmldata, 'html.parser')\n",
        "\treturn(soup)\n",
        "\n",
        "def job_data(soup):\n",
        "\tdata_str = \"\"\n",
        "\n",
        "\tfor item in soup.find_all(\"a\", class_=\"jobtitle turnstileLink\"):\n",
        "\t\tdata_str = data_str + item.get_text()\n",
        "\tresult_1 = data_str.split(\"\\n\")\n",
        "\treturn(result_1)\n",
        " \n",
        "def company_data(soup):\n",
        "\tdata_str = \"\"\n",
        "\tresult = \"\"\n",
        "\tfor item in soup.find_all(\"div\", class_=\"sjcl\"):\n",
        "\t\tdata_str = data_str + item.get_text()\n",
        "\tresult_1 = data_str.split(\"\\n\")\n",
        "\tres = []\n",
        "\tfor i in range(1, len(result_1)):\n",
        "\t\tif len(result_1[i]) > 1:\n",
        "\t\t\tres.append(result_1[i])\n",
        "\treturn(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Driver Module/ Main Function:\n",
        "\n",
        "\n",
        "*   URL for some keywords for Open Science\n",
        "*   Pass this URL into soup which will return HTML string.\n",
        "\n",
        "*   Call job and company data and store into it var.\n",
        "*   Traverse the both data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lTTEESV5bhVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  Location = \"USA\"\n",
        "  keyword = [\"open+science\", \"open+source\", \"open+data\", \"open+access\",\"interdisciplinary\",\"citizen+science\",\"open+research\",\"open+scholarship\"]\n",
        "  for i in keyword:\n",
        "    url = \"https://www.indeed.com/jobs?q=\"+i+\"&l=\"+Location\n",
        "  soup = html_code(url)\n",
        "  job_res = job_data(soup)\n",
        "  com_res = company_data(soup)\n",
        "  temp = 0\n",
        "  for i in range(1, len(job_res)):\n",
        "    j = temp\n",
        "    for j in range(temp, 2+temp):\n",
        "      print(\"Comapny Name and Address:\" + com_res[j])\n",
        "    temp = j\n",
        "  print(\"-------------------\")\n",
        "  print(\"Job:\",job_res)\n",
        "  print(\"-------------------\")"
      ],
      "metadata": {
        "id": "LEp6c9OE5RNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}