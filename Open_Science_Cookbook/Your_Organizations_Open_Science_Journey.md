# Guide for Your Organization's Open Science Journey

In recent decades, the technological barriers to participating in open science have decreased, but barriers due to policy, bureaucracy, funding, and culture remain. Fully engaging with open science is thus dependent on individuals entering into dialogue with their institutions, universities, agencies and companies to identify changes--both small and large--which will support the movement towards open science. 

Building on the work of others over the past several years, TOPS invites individuals, agencies, academic institutions and other organizations to examine the kind of science which they support and encourage, and move towards a more open framework. Join us in our journey, and encourage the pursuit of open scientific progress!  

Suggestions for how to get those in your organization excited about open science are in **[Section 1: Engage with Open Science](./Your_Organizations_Open_Science_Journey.md#section-1-engage-with-open-science)**.

Ready to have some tough discussions and set new policy? Jump ahead to **[Section 2: Strengthen Open Science](./Your_Organizations_Open_Science_Journey.md#section-1-strengthen-open-science)** for discussion prompts and guidelines for creating an organizational open science action plan.

## Is your entire organization ready to embark on an open science journey? 

## Section 1: Engage with Open Science

### Highlight Open Science in Your Organization
Consider your organization’s current open science practice: do researchers use or share open-source code, are pre-prints encouraged or required, is data added to a database or are studies pre-registered? What policies are in place regarding sharing code, instrument data, user surveys, methodology and results? How about instructions regarding licenses and copyrights? 

Those beginning their open science journey often worry that they aren’t truly engaging in “open science” if they are unable to practice openness in every way. At TOPS, we believe it is better to get started and do what you can, than let perfect be the enemy of progress. Show those at your organization how you are beginning an open science journey, by making it easier for everyone to find and access the relevant resources and policies.   

**Get Started** 

Start by examining official policies that are already in place, including any that mention pre-registration, pre-prints, open access, code, data, research artifacts, publication, licenses, copyrights, meta-data, persistent digital identifiers, digital object identifiers, and/or collaboration. Collect the relevant policies in one location and, if possible, write a “directory” to passages in these policies that align with open science principles. Next, examine any “unofficial” policies; what are the research norms at your organization? Can any be updated to be more inclusive, equitable, accessible, or transparent? Address some of these, as appropriate, in a statement that accompanies the new open science directory.  

When highlighting how your organization is already engaging in open science, you are doing more than just sharing projects that were done according to open science principles; you are also giving those just beginning their open science journey a model to follow. Therefore, to ensure the success of these researchers, we recommend the following be included in the blog, web-page, or meeting in which you list the relevant policies and practices:
* Directory of organizational policies which include open science principles 
* Examples (provide links) of publications that followed the open science policies that you are highlighting. The projects chosen may not be good examples of every open science principle, and that is okay! Describe what was done well, and point to the relevant organizational practice and/or policy. 

### Join the TOPS Movement
To help catalyze the move to open science and support changing cultural norms, NASA is championing the Transform to Open Science (TOPS) mission. As part of that mission, NASA has decreed that [**2023 as the Year Of Open Science**](/Year_of_Open_Science_Cookbook/readme.md). But it does not stop there. TOPS is a growing, global initiative rooted in community values that aims to spark change and inspire broad open science engagement. Through TOPS [four areas of action](https://github.com/nasa/Transform-to-Open-Science#implementation), the mission will increase awareness about open science, provide learning resources, and host and co-host events to support a cultural transition to open science. 

**Through collaboration with other organizations, NASA will support and enable the scientific community to move towards open science.** The following list of planned activities represents the areas in which TOPS aims to take action to transform towards open science. If you and your organization are ready to add your strength--via your people, resources, and work--to this transformation, we invite you to join us in these areas of action. 

#### TOPS Planned Activities
  
  1. Promoting   a   common   understanding   of   open   science,   associated   benefits   and   challenges, as well as diverse paths to open science.
       * Increase open science visibility through high-level support and communication strategies, give colloquia, and build partnerships with companies, philanthropic groups, organizations, and institutions to advance open science activities.
  2. Developing an enabling policy environment for open science.
       * The TOPS team will provide advice and guidance to agencies and organizations on targeted policy adjustments to allow for open science activities by federal employees and contractors.
  3. Investing in open science infrastructures and services.
       * Support development of an open science infrastructure center of excellence that has a strong community-led base to advance interoperability and inclusivity, and can advance open infrastructures and FAIR Analysis-Ready Cloud-Optimized (ARCO) data and software.
  4. Investing in human resources, education, digital literacy and capacity building for open science.
       * Support development of an open science education center of excellence that has a strong community-led base to advance open science literacy. Massive Open Online Courses (MOOCs), collaboratively develop curriculum on open science and data science skills with open science certificates and badges. 
       * Leverage existing investments in training and support summer internships, summer schools, HackWeeks, Open Science Launchpads, and challenges.
  5. Aligning incentives and fostering a culture of open science.
       * Create open science awards, highlight successes, and integrate open science community building and practices into performance evaluations, research awards, and reporting.
  6. Promoting innovative approaches for open science at different stages of the scientific process.
       * Integrate open science practices into citizen science, provide a free, low-barrier path to large-scale research infrastructures (e.g. interactive notebook deployments on commercial clouds).
  7. Promoting international and multi stakeholder cooperation in the context of open science and in view of reducing digital and knowledge gaps.
       * Engage with international partners to participate in joint activities around open science, including open infrastructures, open MOOCs, international awards, and open metrics.

### Declare a Year of Open Science
Strengthen NASA's Year of Open Science through the activitives we have provided here. Or go further and *also* declare 2023 the Year of Open Science for your organization! Join us at [conferences](/Year_of_Open_Science_Cookbook/conferences_for_the_year_of_open_science.md), create awards, and make available funding to advance open science. 

## Section 2: Strengthen Open Science 

### Open Science Action Plans

Open Science Action Plans (OSAPs) are comprehensive strategy documents designed to advance adoption of open science practices. They should document 

(1) what an organization is doing well, 

(2) where there are areas for improvement, and 

(3) detail specific actions that the organization will take to address the areas of improvement. 

Some organizations may be hesitant to publicly commit themselves to OSAPs; it can be difficult to admit areas where there is still work to be done. Part of adopting open science is becoming more comfortable sharing our failures -- as individuals and organizations -- as well as our successes. Honestly sharing a current status, publishing lessons learned, and announcing ideas for moving forward are exactly the open science practices that TOPS and the greater open science community are advocating scientists adopt. 

One possible starting point for an OSAP  is to use the [UNESCO Recommendation on Open Science](https://en.unesco.org/science-sustainable-future/open-science/recommendation) which sets out 7 areas of action to advance open science. Within that report, there are specific examples for different types of organizations. 

These areas of action are:
* Promoting   a   common   understanding   of   open   science,   associated   benefits   and   challenges, as well as diverse paths to Open Science
* Developing an enabling policy environment for open science
* Investing in open science infrastructures and services
* Investing in human resources, education, digital literacy and capacity building for open science
* Fostering a culture of open science and aligning incentives for open science
* Promoting innovative approaches for open science at different stages of the scientific process
* Promoting  international  and  multistakeholder  cooperation  in  the  context  of  open  science, and in view of reducing digital and knowledge gaps

UNESCO also [provided guidance](https://en.unesco.org/science-sustainable-future/open-science/recommendation) to consider “the development of a monitoring framework with qualitative and quantitative indicators, within national strategic plans and shared at the international level, with objectives and actions in the short, medium and long term for the implementation of the present.” 

Once an ‘open science plan’ is developed, ideally it is shared publicly along with a dashboard that shows progress with clearly defined metrics. Some example activities that could be a part of that plan are:
* **Science Associations:** Designate 1 day of annual meetings to focus on open science education. This could include workshops, tutorials, and showcases, and should aim to represent all the aspects of participating in and contributing to open science. This would reach a large percentage of the scientific community and create an urgency around learning to use these new tools to conduct research. Advance ability to publish software research notebooks alongside research results. Create open science awards and include open science activities in criteria for existing honors where possible. Allow award nominations to include teams. 
* **Federal Agencies:** Designate 1 day each month to advance open science practices. Remove bureaucratic barriers to open science, incentivise open science activities, and provide training opportunities for learning open science tools. Update agency evaluation and promotion criteria and guidelines to better enable participation in open science. Set agency workforce training goals aligned with doing open science and learning the tools to work collaboratively and openly. 
* **Institutions:** Update evaluation and promotion criteria to include recognition of open science activities. Incorporate open science best practices into graduate and undergraduate curricula. Update intellectual property guidelines to align with open initiatives. Develop open science cohorts within departments to support the move towards openness. Develop open science practices and encourage the use of collaborative cloud computing environments for research.

### Discuss Your Policies and Practices
It can be a bit difficult to know when to begin when you are updating existing operating procedures to include open science. Using [these guiding documents](./Your_Organizations_Open_Science_Journey.md#citing-our-sources) we have put together a list of "food for thought" questions to discuss with leaders, colleagues, and stakeholders 

#### Discuss: Research and Data Products
* Consider the data held in trust by your organization. 
    * Where can researchers find your data? What is your process/method for releasing data? Can portions of it be anonymized such that it can be shared? Is the process for requesting access to your data clear? How fast is the data request process and how often do you go through the process of releasing data? Does your organization have practices around pre-registration and archiving? Are these practices well-known and front-of-mind?
    * [Registry of Research Data Repositories](https://www.re3data.org/) is an example site for finding open databases 
* If your organization produces research, consider if:
    * Research plans may be made available, prior to the start of the project, 
    * That reproducibility/replicability studies be valued and encouraged, and
    * That null/negative results be published. 
    * Some examples of making research plans available can be found at [AsPredicted](https://aspredicted.org/), [Open Science Framework](https://osf.io/), and [Registered Reports](https://cos.io/rr/) 
    * Examples of journals that publish negative/nul results include Positively Negative (PLOS One), The Missing Pieces: A Collection of Negative; Null and Inconclusive Results (PLOS One), The All Results Journals, ACS Omega (ACS Publications), F1000Research, PeerJ, Journal of Negative Results in Biomedicine, Journal of Negative Results: Ecology and Evolutionary Biology, Journal of Articles in Support of the Null Hypothesis, Journal of Pharmaceutical Negative results and Nature Scientific Reports
    * Examples of journals that publish reproducibility/replicability studies are PLOS ONE, and [Royal Society](https://royalsocietypublishing.org/rsos/replication-studies)
* For research produced *for* your organization: 
    * Do you require that the list of materials, study methods, and computational environment be included in the final results which are shared publicly? If not, consider making this a requirement of the project. 
* For data or research produced *by* your organization: 
    * In what languages is the research available? Are bilingual researchers encouraged to apply for funding? Or, better yet, publish in multiple languages? 
    * Consider adding extensions to your databases, publication sites, or other methods of sharing data to allow for easy translation into other languages. 
* Does your organization develop software? 
    * Can this code be made publicly available via GitHub, BitBucket or other mechanisms? 
    * Consider how much of the work of your group ought to be kept “closed” and how much can be made available to advance the work of others, particularly young professionals and early career researchers.
  
#### Discuss: Metrics and Incentives

* If your organization conducts research, consider the metrics used when evaluating professors, researchers, lab assistants etc. for promotions and opportunities. 
    * What do these metrics *actually* measure? Do these metrics account for historic bias, institutional bias, or other inclusivity or accessibility considerations? Do these metrics account for time and effort spent on research that ultimately produced null and/or negative results? 
    * Explore using alternative metrics that value transparency, reproducibility, replicability, and access. In particular, consider metrics which reflect readability and accessibility of software, code, and data, to encourage and reward researchers who spend time and resources on data science principles 
    * To learn more about this topic, explore work by [Fire and Guestrin](https://academic.oup.com/gigascience/article/8/6/giz053/5506490); [Beall](https://pubs.acs.org/doi/10.1021/acs.jpclett.5b00910); and [Carpenter, Cone and Sarli](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4987709/) in analyzing the impact of traditional metrics for journal publications and research merit 
* Does your institution incentive and reward researchers in which the primary output of the research is code or software development? Consider highlighting work which results in “good code” and valuing publication in “code first” journals equally to those published in other, more traditional journals. 
    * The Journal of Open Source Software and Journal of Open Research Software are two examples of journals which allow for the "traditional" publication of code
  * According to [Suominen *et al*](https://doi.org/10.1016/j.techfore.2021.120882) motivating forces for researchers and scientists are “curiosity, good practice, high-quality science, and making a difference” while de-motivating factors include “collaboration problems, competition, and lack of feedback and recognition for management.” The article goes on to conclude that motivating factors tend to be intrinsic, while the de-motivating factors were often environmental at the organization where the researcher worked. 
  * Consider your organization’s current incentive and recognition structure: is it recognizing motivating factors in those it hires, promotes and praises?
  *  Consider the overall structure for management of research: are any of the de-motivating factors present? Such factors can be minimized by providing researchers with opportunities (both informal and formal) to network, ask for and receive constructive feedback and share their work with those in other fields in addition to their own. 
* It is the suggestion of the [National Academy of Sciences](https://doi.org/10.17226/26308https://doi.org/10.17226/26308) that organizations which are committed to moving towards and advocating for open science should consider the language which is used not only in grants and calls for proposals, but also in prompts for cover letters and resumes, to ensure that the ethos of open science is consistently present. 
    * For example, are applicants for a job asked about their commitment to open science in their recent work? Are post-docs encouraged to make their data open when conducting their work? 
    * An excellent resource on this topic can be found in the [National Academies of Sciences, Engineering, and Medicine. 2021. Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop. Washington, DC: The National Academies Press](https://doi.org/10.17226/26308). 


#### Discuss: Representation, Mentoring & Training

* What is the “signaling language” used in grant applications, job postings, and descriptions of research conducted at your organization? 
    * Does this language imply open or closed science practice? Consider updating language where appropriate. 
    * In particular, if your organization has an employee or researcher handbook, review it for language that signals a preference for open or closed science practices. For example, stressing commercialization of ideas encourages people to *not* share their findings in case it could become valuable intellectual property or trade secrets in the future. In contrast, stressing the data sharing can directly enforce an open science ethos. 
* If your organization hires post-docs: are the postdocs also encouraged to engage in open science, or are they measured against different metrics than other researchers? 
* If your organization provides or manages funds for research, consider how the funds are used. Beyond producing results, are funds used for…
    * Research at the intersection of science and society? 
    * Research done by underrepresented/minority researchers? 
    * Research done to directly support underrepresented/minority communities?
    * Research done by early career researchers? 
    * Research done by students (undergraduate and graduate levels)? 
    * Research done to replicate and/or reproduce other studies?
    * Research that produces code? (And do the requirements maintain that this code must be Findable, Accessible, Interoperable, Reusable?)
    * Research that produces data? (And do the requirements maintain that the data must be properly assigned metadata and be made available alongside the results OR prior to the results being published OR in a publicly accessible database so that others may use it?)  
    * Research in which the primary result is code or software development? 
* Does your organization provide training in open science practices such as the use of open databases, or the sharing of open-source software? How about training in bias and anti-bias practices both in the distribution of funding, and in the interpretation of research results (e.g., data dredging, p-hacking and HARK-ing)? 
    * Consider adopting and adapting the [TOPS Open Science curriculum](/docs/Area2_Capacity_Sharing/OpenCore/readme.md), the work of the European Union’s [FOSTER project](https://www.fosteropenscience.eu/toolkit) or/and what has been done by the [Berkeley Initiative for Transparency in the Social Sciences (BITSS)](https://www.bitss.org/resource-library/) to your needs and incentivizing funded researchers to learn more about open science. 
* Does your organization have access to makerspaces? 
    * Who can use them? Are they open to all or only to a certain group? 
    * Consider creating a pathway for community members–particularly high schoolers, study teams organized via libraries, Girl and Boy Scouts, YMCAs, and other organized youth groups–to be able to apply to use these spaces.
* Does your organization have a structured mentoring program for early career researchers? If not, consider creating one. If one already exists, consider incorporating themes of open science into the program.

#### Additional Recommendations for Academic Institutions

Some recommendations are most appropriate for academic institutions to tackle, as they relate to academic coursework. We have listed a few of these here, and additionally invite those interested to explore the [Open-Access recommendations by MIT](https://mitl.pubpub.org/pub/future-of-libraries/release/1).

* Are both undergraduate and graduate students required to learn about proper statistical analysis and inference? 
    * In particular, do your students understand common problems with statistical analysis which can lead to a lack of accessibility, replicability, and/or reproducibility of the results (e.g., p-hacking, cherry-picking)? 
    * Consider making such knowledge a central tenet of STEM courses at both the undergraduate and graduate levels. 
* For researchers who conduct “field work:” 
    * How do they work with the communities in the field they are studying? If they are being immersed into a community, culture and/or society other than their own, what are your institution's practices and suggestions for that interaction? Are they required to know the language? Study the history and context? Are they required to have partners who are of that community, culture and/or society on their research team? 
    * Consider if your institution may benefit from adjusting the metrics for success in these situations, to include time and incentive for researchers to fully engage with the people most closely affected–either directly or indirectly–by their work. 
    * On a related note, are STEM majors and those pursuing graduate studies in STEM encouraged to study other languages and/or cultures? Are the requirements for a major structured in such a way that they have room in their schedules to pursue those interests? Studying other languages can be a great way to begin to understand the motivations of another community. Next time you review requirements, consider this: what do the requirements of these majors teach students about what is important? 
* We invite academic institutions to read the work of [MIT’s Future of the Libraries Task Force](https://mitl.pubpub.org/pub/future-of-libraries/release/1) from 2016 and consider whether those recommendations, particularly those related to open access, are applicable to your library system.


### Citing Our Sources
Recommendations for this page were pulled from the following publications. Thank you to the contributors, authors, and editors of these reports for sharing the power of open science with the world.
* National Academies of Sciences, Engineering, and Medicine 2018. Open Science by Design: Realizing a Vision for 21st Century Research. Washington, DC: The National Academies Press. [https://doi.org/10.17226/25116](https://doi.org/10.17226/25116).
* OA Task Force, Mit and Katharine Dunn. 2018. “Open Access at MIT and Beyond.” MIT Open Access Task Force. [https://open-access.mit.edu/sites/default/files/20180917_Provost_OpenAccessTF_WhitePaper.pdf](https://open-access.mit.edu/sites/default/files/20180917_Provost_OpenAccessTF_WhitePaper.pdf) 
* National Academies of Sciences, Engineering, and Medicine 2019. Reproducibility and Replicability in Science. Washington, DC: The National Academies Press. [https://doi.org/10.17226/25303](https://doi.org/10.17226/25303). 
* Open Tech Strategies 2019. Open Source Archetypes: A Framework For Purposeful Open Source. [https://opentechstrategies.com/archetypes](https://opentechstrategies.com/archetypes) 
* Fogel, Karl 2020. Producing Open Source Software How to Run a Successful Free Software Project. [https://producingoss.com/en/social-infrastructure.html](https://producingoss.com/en/social-infrastructure.html#forkability) 
* Hampson, Glenn et al. 2020. “Open Science Roadmap: Recommendations to UNESCO.” [https://doi.org/10.13021/osi2020.2735](https://doi.org/10.13021/osi2020.2735) 
* National Academies of Sciences, Engineering, and Medicine. 2021. Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop. Washington, DC: The National Academies Press. [https://doi.org/10.17226/26308](https://doi.org/10.17226/26308). 
* Suominen, Arho. Kauppinen, Henni. Hyytinen, Kirsi. 2021. ‘Gold’, ‘Ribbon’ or ‘Puzzle’: What motivates researchers to work in Research and Technology Organizations. Technological Forecasting & Social Change. [https://doi.org/10.1016/j.techfore.2021.120882](https://doi.org/10.1016/j.techfore.2021.120882) 
* UNESCO. 2021. UNESCO Recommendation on Open Science. [https://en.unesco.org/science-sustainable-future/open-science/recommendation](https://en.unesco.org/science-sustainable-future/open-science/recommendation) 
* Martin S. Hagger (2022) Developing an open science ‘mindset’, Health Psychology and Behavioral Medicine, 10:1, 1-21, DOI: 10.1080/21642850.2021.2012474. [https://doi.org/10.1080/21642850.2021.2012474](https://doi.org/10.1080/21642850.2021.2012474)  
* Miedema, Frank 2022. Open Science: The Very Idea. Utrecht, The Netherlands: Springer Nature. [https://doi.org/10.1007/978-94-024-2115-6](https://doi.org/10.1007/978-94-024-2115-6)

## Get Involved in the Year of Open Science
Ready to talk to others about your organization's open science journey? Excited to learn more about open science at NASA? [Join in](/Year_of_Open_Science_Cookbook/readme.md) on the activities for 2023 the Year of Open Science!
