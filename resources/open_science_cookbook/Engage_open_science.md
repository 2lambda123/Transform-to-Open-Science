# Engage with Open Science 
After deepening your or your organization's understanding of open science, existing policies or practices regarding research may seem as if they need to be updated. **Engage** with open science by asking the following questions, and considering the next steps that can be taken to adopt open science throughout your research practice or organization. 

## What can organizations do to change their open science mindset? 

Recent advances have reduced many of the *technological barriers* to participating in open science, but other barriers remain. Many scientists are still unable to contribute because of outdated institutional policies around sharing information, a lack of support to transition towards openness, or because they lack open science skills. The transformation to open science must be enabled by support from the institutions and organizations. 

Building on the work of others over the past several years, TOPS invites individuals, agencies, academic institutions and other organizations to examine the kind of science which they support and encourage, and move towards a more open framework. Join us in our journey, and encourage the pursuit of open scientific progress!  

<details>
  <summary><h3>Sources and Recommended Reading</h3></summary>

Sources and inspiration for the following suggestions were curated from the work presented in the following publications. Thank you to the contributors, authors, and editors of these reports for sharing the power of open science with the world.

Articles are arranged chronologically and then alphabetically by author/authoring organization. 
* National Academies of Sciences, Engineering, and Medicine 2018. Open Science by Design: Realizing a Vision for 21st Century Research. Washington, DC: The National Academies Press. [https://doi.org/10.17226/25116](https://doi.org/10.17226/25116).
* OA Task Force, Mit and Katharine Dunn. 2018. “Open Access at MIT and Beyond.” MIT Open Access Task Force. [https://open-access.mit.edu/sites/default/files/20180917_Provost_OpenAccessTF_WhitePaper.pdf](https://open-access.mit.edu/sites/default/files/20180917_Provost_OpenAccessTF_WhitePaper.pdf) 
* National Academies of Sciences, Engineering, and Medicine 2019. Reproducibility and Replicability in Science. Washington, DC: The National Academies Press. [https://doi.org/10.17226/25303](https://doi.org/10.17226/25303). 
* Open Tech Strategies 2019. Open Source Archetypes: A Framework For Purposeful Open Source. [https://opentechstrategies.com/archetypes](https://opentechstrategies.com/archetypes) 
* Fogel, Karl 2020. Producing Open Source Software How to Run a Successful Free Software Project. [https://producingoss.com/en/social-infrastructure.html](https://producingoss.com/en/social-infrastructure.html#forkability) 
* Hampson, Glenn et al. 2020. “Open Science Roadmap: Recommendations to UNESCO.” [https://doi.org/10.13021/osi2020.2735](https://doi.org/10.13021/osi2020.2735) 
* National Academies of Sciences, Engineering, and Medicine. 2021. Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop. Washington, DC: The National Academies Press. [https://doi.org/10.17226/26308](https://doi.org/10.17226/26308). 
* Suominen, Arho. Kauppinen, Henni. Hyytinen, Kirsi. 2021. ‘Gold’, ‘Ribbon’ or ‘Puzzle’: What motivates researchers to work in Research and Technology Organizations. Technological Forecasting & Social Change. [https://doi.org/10.1016/j.techfore.2021.120882](https://doi.org/10.1016/j.techfore.2021.120882) 
* UNESCO. 2021. UNESCO Recommendation on Open Science. [https://en.unesco.org/science-sustainable-future/open-science/recommendation](https://en.unesco.org/science-sustainable-future/open-science/recommendation) 
* Martin S. Hagger (2022) Developing an open science ‘mindset’, Health Psychology and Behavioral Medicine, 10:1, 1-21, DOI: 10.1080/21642850.2021.2012474. [https://doi.org/10.1080/21642850.2021.2012474](https://doi.org/10.1080/21642850.2021.2012474)  
* Miedema, Frank 2022. Open Science: The Very Idea. Utrecht, The Netherlands: Springer Nature. [https://doi.org/10.1007/978-94-024-2115-6](https://doi.org/10.1007/978-94-024-2115-6)
</details>

### Recommendations for Government Organizations, Academic Institutions and NGOs
Recommendations are grouped by theme, with recommended reading or places where more information can be found included where it may be helpful. 


#### Research Products & Data
* Consider the data held in trust by your organization. Where can researchers find your data? What is your process/method for releasing data? Can portions of it be anonymized such that it can be shared? Is the process for requesting access to your data clear? How fast is it and how often do you go through the process of releasing data? Does your organization have practices around pre-registration and archiving? Are these practices well-known and front-of-mind?
    * We highlight **[Registry of Research Data Repositories](https://www.re3data.org/)** as a location for finding open databases 
* If your organization produces research, require that research plans be made available, prior to the start of the project, and that null/negative results be published. 
    * We highlight [AsPredicted](https://aspredicted.org/), [Open Science Framework](https://osf.io/), and [Registered Reports](https://cos.io/rr/) as locations for making research plans available 
    * We highlight _Positively Negative (PLOS One), The Missing Pieces: A Collection of Negative; Null and Inconclusive Results (PLOS One), The All Results Journals, ACS Omega (ACS Publications), F1000Research, PeerJ, Journal of Negative Results in Biomedicine, Journal of Negative Results – Ecology and Evolutionary Biology, Journal of Articles in Support of the Null Hypothesis, Journal of Pharmaceutical Negative results,_ and _Nature Scientific Reports_ as locations where negative/null results are published
    * We highlight _PLOS ONE_, and _[Royal Societ](https://royalsocietypublishing.org/rsos/replication-studies)y _as locations for reproducibility/replicability studies
    * We suggest [“Developing an Open Science Mindset” by Martin Hagger](https://www.researchgate.net/publication/357349563_Developing_an_open_science_'mindset') as further reading
* For research produced for your organization: do you require that the list of materials, study methods, and computational environment be included in the final results which are shared publicly? If not, consider making this a requirement of the project. 
* For organizations which produce data and/or research, in what languages is the research available? Are bilingual researchers encouraged to apply for funding? Or, better yet, publish in multiple languages? Consider adding extensions to your databases, publication sites, or other methods of sharing data to allow for easy translation into other languages. 
* Does your organization develop software? Can this code be made publicly available via GitHub, BitBucket or other mechanisms? Consider how much of the work of your group ought to be kept “closed” and how much can be made available to advance the work of others, particularly young professionals and early career researchers. 
* Consider joining the open access movement by groups such as SPARC in asking for blanket, open-access policies and the United States: [https://sparcopen.org/our-work/us-national-open-access-policy/](https://sparcopen.org/our-work/us-national-open-access-policy/) 

#### Metrics & Incentives
* If your organization conducts research, consider the metrics used when evaluating professors, researchers, lab assistants etc. for promotions and opportunities. Ask yourselves, what do these metrics _actually _measure? Do these metrics account for historic bias, institutional bias, or other inclusivity or accessibility considerations? What about null and/or negative results? Explore using alternative metrics that value transparency, reproducibility, replicability, and access.
    * In particular, we suggest the adoption of metrics which reflect readability and accessibility of software, code and/or data, to encourage and reward researchers who spend time and resources on data science principles 
    * We suggest work done by [Fire and Guestrin](https://academic.oup.com/gigascience/article/8/6/giz053/5506490); [Beall](https://pubs.acs.org/doi/10.1021/acs.jpclett.5b00910); and [Carpenter, Cone and Sarli](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4987709/) in analyzing the impact of traditional metrics for journal publications and research merit as further reading 
* According to Suominen _et al _([article link](https://doi.org/10.1016/j.techfore.2021.120882)) motivating forces for researchers and scientists are “curiosity, good practice, high-quality science, and making a difference” while de-motivating factors include “collaboration problems, competition, and lack of feedback and recognition for management.” The article goes on to conclude that motivating factors tend to be intrinsic, while the de-motivating factors were often environmental at the organization where the researcher worked. 
    * Consider your organization’s current incentive and recognition structure: is it recognizing motivating factors in those it hires, promotes and praises? 
    * Consider the overall structure for management of research: are any of the de-motivating factors present? Such factors can be minimized by providing researchers with opportunities (both informal and formal) to network, ask for and receive constructive feedback and share their work with those in other fields in addition to their own. 
* It is the suggestion of the National Academy of Sciences ([article link](https://doi.org/10.17226/26308https://doi.org/10.17226/26308)) that organizations which are committed to moving towards and advocating for open science should consider the language which is used not only in grants and calls for proposals, but also in prompts for cover letters and resumes, to ensure that the ethos of open science is consistently present. For example, are applicants for a job asked about their commitment to open science in their recent work? Are post-docs encouraged to make their data open when conducting their work? 
    * An excellent resource on this topic can be found in the National Academies of Sciences, Engineering, and Medicine. 2021. Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop. Washington, DC: The National Academies Press. [https://doi.org/10.17226/26308](https://doi.org/10.17226/26308). 
* Does your institution incentive and reward researchers in which the primary output of the research is code or software development? Consider highlighting work which results in “good code” and valuing publication in “code first” journals equally to those published in other, more traditional journals. 
    * We highlight the _Journal of Open Source Software_ and _Journal of Open Research Software_ as two journals which allow for the publication of code via “traditional” settings.

#### Engaging in Research & Training

* What is the “signaling language” used in grant applications, job postings, and descriptions of research conducted at your organization? Does this language imply open or closed science practice? Consider updating language where appropriate. 
    * In particular, if your organization has an employee or researcher handbook, review it for language that signals a preference for open or closed science practices. For example, stressing commercialization of ideas encourages people to _not _share their findings in case it could become valuable intellectual property or trade secrets. While stressing the open sharing of data can directly enforce an open science ethos. 
* If your organization hires post-docs: are the postdocs also encouraged to engage in open science, or are they measured against different metrics than other researchers? 
* If your organization provides or manages funds for research, ask yourself, how do researchers use your money? Beyond producing results, do you set aside money for…
    * Research at the intersection of science and society? 
    * Research done by underrepresented/minority researchers? 
    * Research done _to directly support _underrepresented/minority _communities? _
    * Research done by early career researchers? 
    * Research done by students (undergraduate and graduate levels)? 
    * Research done to replicate and/or reproduce other studies?
    * Research that produces code? (Do the requirements maintain that this code must be Findable, Accessible, Interoperable, Reusable (FAIR)?)
    * Research that produces data? (Do the requirements maintain that the data must be properly assigned metadata and be made available (a) alongside the results, (b) prior to the results being published, (c) in a publicly accessible database so that others may use it?)  
    * Research in which the primary result is code or software development? 
* Does your organization provide training in open science practices such as the use of open databases, or the sharing of open-source software? How about training in bias and anti-bias practices both in the distribution of funding (who/which institutions_ _gets the funding), and in the interpretation of research results (data dredging, p-hacking and HARK-ing)? 
    * Consider adopting and adapting the TOPS Open Science curriculum, ​​the work of the European Union’s FOSTER project or/and what has been done by the Berkeley Initiative for Transparency in the Social Sciences (BITSS) to your needs and incentivizing funded researchers to learn more about open science. 
* Does your organization have access to makerspaces? Who can use them? Are they open to all or only to a certain group? Consider creating a pathway for community members–particularly high schoolers, study teams organized via libraries, Girl and Boy Scouts, YMCAs, and other organized youth groups–to be able to apply to use these spaces.
* Does your organization have a structured mentoring program for early career researchers? If not, consider creating one. If one already exists, consider incorporating themes of open science into the program. 

# Additional Recommendations for All



* We invite all our partners to read and adapt the recommendations from the National Academies of Sciences, Engineering, and Medicine workshop in 2021, “Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop.” Which can be found at [https://doi.org/10.17226/26308](https://doi.org/10.17226/26308). In particular, the Toolkit Materials in Appendix C provide resources for:
    * Drafting an institution statement of support for open science methods and practices (pages 33 to 45)
    * Examples of successful and impactful open science work such as the Human Genome Project and the COVID-19 Open Research Dataset (pages 36 to 39)
    * A sample template and rubric for assessing a grant/job application for adherence to open science principles (pages 46 to 69)
    * A series of short primers on various open-science topics (pages 70 to 92)


# Additional Recommendations for Academic Institutions

Some recommendations are most appropriate for academic institutions to tackle, as they relate to academic coursework. We have listed a few of these here, and additionally invite those interested to explore the Open-Access recommendations by MIT at [https://mitl.pubpub.org/pub/future-of-libraries/release/1](https://mitl.pubpub.org/pub/future-of-libraries/release/1). 



* Are both undergraduate and graduate students required to learn about proper statistical analysis and inference? In particular, do your students understand common problems with statistical analysis which can lead to a lack of accessibility, replicability, and/or reproducibility of the results (e.g., p-hacking, cherry-picking)? Consider making such knowledge a central tenet of STEM courses at both the undergraduate and graduate levels. 
* For researchers who conduct “field work;” how do they work with the communities in the field they are studying? If they are being immersed into a community, culture and/or society other than their own, what are your institution's practices and suggestions for that interaction? Are they required to know the language? Study the history and context? Are they required to have partners who are of that community, culture and/or society on their research team? Consider if your institution may benefit from adjusting the metrics for success in these situations, to include time and incentive for researchers to fully engage with the people most closely affected–either directly or indirectly–by their work. 
    * Related: Are STEM majors and those pursuing graduate studies in STEM encouraged to study other languages and/or cultures? Are the requirements for a major structured in such a way that they have room in their schedules to pursue those interests? Studying other languages can be a great way to begin to understand the motivations of another community. Next time you review requirements, consider this: what do the requirements of these majors teach our students about what is important? 
* We invite academic institutions to read the work of [MIT’s Future of the Libraries Task Force](https://mitl.pubpub.org/pub/future-of-libraries/release/1) from 2016 and consider whether those recommendations, particularly those related to open access, are applicable to your library system.
